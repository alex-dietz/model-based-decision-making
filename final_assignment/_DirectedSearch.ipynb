{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Search\n",
    "Likely to be MORDM\n",
    "1) Initialize Model/ Problem Specification\n",
    "2) Search Candidate Solutions (based on Ref Scenario)\n",
    "3) Re-Evaluate Solutions under Uncertainty (Many Scenario)\n",
    "4) Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/ema_workbench/analysis/prim.py:30: ImportWarning: altair based interactive inspection not available\n",
      "  warnings.warn((\"altair based interactive \" \"inspection not available\"), ImportWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# EMA\n",
    "from ema_workbench import (Model, RealParameter,  Scenario, MultiprocessingEvaluator, ScalarOutcome, perform_experiments, ema_logging)\n",
    "from ema_workbench import Samplers, Policy\n",
    "from ema_workbench import save_results, load_results\n",
    "from ema_workbench.em_framework.optimization import EpsilonProgress, HyperVolume\n",
    "from ema_workbench.analysis import parcoords\n",
    "# Model\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------- Set Model Parameters\n",
    "problem_formulation = 6\n",
    "model, steps = get_model_for_problem_formulation(problem_formulation)\n",
    "\n",
    "uncertainties = model.uncertainties\n",
    "levers = model.levers\n",
    "outcomes = model.outcomes\n",
    "\n",
    "#------------------------- Reference Scenario\n",
    "ref_val = {'Bmax': 175, \n",
    "           'Brate': 1.5, \n",
    "           'pfail': 0.5,\n",
    "            'discount rate': 3.5,\n",
    "            'ID flood wave shape': 4}\n",
    "\n",
    "ref_dict = {}\n",
    "# < ref_dict >\n",
    "# reference scenario updated for all dike rings\n",
    "for key in model.uncertainties:\n",
    "    name_split = key.name.split('_')\n",
    "    if len(name_split) == 1:\n",
    "        if key.name in ref_val.keys():\n",
    "            ref_dict.update({key.name: ref_val[key.name]})\n",
    "    else:\n",
    "        ref_dict.update({key.name: ref_val[name_split[1]]})\n",
    "\n",
    "\n",
    "#------------------------- Optimization Parameters\n",
    "\n",
    "ref_scenario = Scenario('reference', **ref_dict)\n",
    "\n",
    "convergence_metrics = [EpsilonProgress()]\n",
    "nfe = 10000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Search Candidate Solutions (based on Ref Scenario)\n",
    "- Run Optimization on Lever Space\n",
    "- Find Candidate Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started with 4 workers\n",
      "100%|████████████████████████████████████▉| 9970/10000 [26:52<00:05,  5.42it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ema_logging\u001b[39m.\u001b[39mlog_to_stderr(ema_logging\u001b[39m.\u001b[39mINFO)\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m MultiprocessingEvaluator(model, n_processes \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m) \u001b[39mas\u001b[39;00m evaluator:\n\u001b[0;32m----> 5\u001b[0m     results1, convergence \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39;49moptimize(nfe\u001b[39m=\u001b[39;49mnfe,\n\u001b[1;32m      6\u001b[0m                                             searchover\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlevers\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m                                             epsilons\u001b[39m=\u001b[39;49m[\u001b[39m0.1\u001b[39;49m]\u001b[39m*\u001b[39;49m\u001b[39mlen\u001b[39;49m(model\u001b[39m.\u001b[39;49moutcomes),\n\u001b[1;32m      8\u001b[0m                                               convergence\u001b[39m=\u001b[39;49mconvergence_metrics,\n\u001b[1;32m      9\u001b[0m                                             reference\u001b[39m=\u001b[39;49mref_scenario\n\u001b[1;32m     10\u001b[0m                                             )\n\u001b[1;32m     12\u001b[0m results1\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mresults/optimization_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(problem_formulation,nfe))\n\u001b[1;32m     14\u001b[0m \u001b[39m#'''\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ema_workbench/em_framework/evaluators.py:248\u001b[0m, in \u001b[0;36mBaseEvaluator.optimize\u001b[0;34m(self, algorithm, nfe, searchover, reference, constraints, convergence_freq, logging_freq, variator, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    232\u001b[0m     algorithm\u001b[39m=\u001b[39mEpsNSGAII,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    241\u001b[0m ):\n\u001b[1;32m    242\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"convenience method for outcome optimization.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m \u001b[39m    is forwarded to :func:optimize, with evaluator and models\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m    arguments added in.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \n\u001b[1;32m    247\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mreturn\u001b[39;00m optimize(\n\u001b[1;32m    249\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_msis,\n\u001b[1;32m    250\u001b[0m         algorithm\u001b[39m=\u001b[39;49malgorithm,\n\u001b[1;32m    251\u001b[0m         nfe\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(nfe),\n\u001b[1;32m    252\u001b[0m         searchover\u001b[39m=\u001b[39;49msearchover,\n\u001b[1;32m    253\u001b[0m         evaluator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    254\u001b[0m         reference\u001b[39m=\u001b[39;49mreference,\n\u001b[1;32m    255\u001b[0m         constraints\u001b[39m=\u001b[39;49mconstraints,\n\u001b[1;32m    256\u001b[0m         convergence_freq\u001b[39m=\u001b[39;49mconvergence_freq,\n\u001b[1;32m    257\u001b[0m         logging_freq\u001b[39m=\u001b[39;49mlogging_freq,\n\u001b[1;32m    258\u001b[0m         variator\u001b[39m=\u001b[39;49mvariator,\n\u001b[1;32m    259\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    260\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ema_workbench/em_framework/evaluators.py:744\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(models, algorithm, nfe, searchover, evaluator, reference, convergence, constraints, convergence_freq, logging_freq, variator, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evaluator:\n\u001b[1;32m    742\u001b[0m     evaluator \u001b[39m=\u001b[39m SequentialEvaluator(models)\n\u001b[0;32m--> 744\u001b[0m \u001b[39mreturn\u001b[39;00m _optimize(\n\u001b[1;32m    745\u001b[0m     problem,\n\u001b[1;32m    746\u001b[0m     evaluator,\n\u001b[1;32m    747\u001b[0m     algorithm,\n\u001b[1;32m    748\u001b[0m     convergence,\n\u001b[1;32m    749\u001b[0m     nfe,\n\u001b[1;32m    750\u001b[0m     convergence_freq,\n\u001b[1;32m    751\u001b[0m     logging_freq,\n\u001b[1;32m    752\u001b[0m     variator\u001b[39m=\u001b[39;49mvariator,\n\u001b[1;32m    753\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    754\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ema_workbench/em_framework/optimization.py:1070\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(problem, evaluator, algorithm, convergence, nfe, convergence_freq, logging_freq, variator, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m evaluator\u001b[39m.\u001b[39mcallback \u001b[39m=\u001b[39m callback\n\u001b[1;32m   1069\u001b[0m \u001b[39mwith\u001b[39;00m temporary_filter(name\u001b[39m=\u001b[39m[callbacks\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, evaluators\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m], level\u001b[39m=\u001b[39mINFO):\n\u001b[0;32m-> 1070\u001b[0m     optimizer\u001b[39m.\u001b[39;49mrun(nfe)\n\u001b[1;32m   1072\u001b[0m convergence(optimizer, force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1074\u001b[0m \u001b[39m# convergence.pbar.__exit__(None, None, None)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/platypus/core.py:407\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[0;34m(self, condition, callback)\u001b[0m\n\u001b[1;32m    404\u001b[0m LOGGER\u001b[39m.\u001b[39mlog(logging\u001b[39m.\u001b[39mINFO, \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m starting\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    406\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m condition(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 407\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    409\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_frequency \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfe \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m last_log \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_frequency:\n\u001b[1;32m    410\u001b[0m         LOGGER\u001b[39m.\u001b[39mlog(logging\u001b[39m.\u001b[39mINFO,\n\u001b[1;32m    411\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m running; NFE Complete: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, Elapsed Time: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m                    \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,\n\u001b[1;32m    413\u001b[0m                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfe,\n\u001b[1;32m    414\u001b[0m                    datetime\u001b[39m.\u001b[39mtimedelta(seconds\u001b[39m=\u001b[39mtime\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart_time))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/platypus/algorithms.py:1521\u001b[0m, in \u001b[0;36mPeriodicAction.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 1521\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgorithm\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m   1522\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miteration \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1523\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm\u001b[39m.\u001b[39mnfe\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/platypus/algorithms.py:182\u001b[0m, in \u001b[0;36mNSGAII.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n\u001b[1;32m    181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterate()\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marchive \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marchive\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/platypus/algorithms.py:205\u001b[0m, in \u001b[0;36mNSGAII.iterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m     parents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselector\u001b[39m.\u001b[39mselect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariator\u001b[39m.\u001b[39marity, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation)\n\u001b[1;32m    203\u001b[0m     offspring\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariator\u001b[39m.\u001b[39mevolve(parents))\n\u001b[0;32m--> 205\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_all(offspring)\n\u001b[1;32m    207\u001b[0m offspring\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation)\n\u001b[1;32m    208\u001b[0m nondominated_sort(offspring)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/platypus/core.py:380\u001b[0m, in \u001b[0;36mAlgorithm.evaluate_all\u001b[0;34m(self, solutions)\u001b[0m\n\u001b[1;32m    377\u001b[0m unevaluated \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m solutions \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s\u001b[39m.\u001b[39mevaluated]\n\u001b[1;32m    379\u001b[0m jobs \u001b[39m=\u001b[39m [_EvaluateJob(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m unevaluated]\n\u001b[0;32m--> 380\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluator\u001b[39m.\u001b[39;49mevaluate_all(jobs)\n\u001b[1;32m    382\u001b[0m \u001b[39m# if needed, update the original solution with the results\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mfor\u001b[39;00m i, result \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(results):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ema_workbench/em_framework/evaluators.py:175\u001b[0m, in \u001b[0;36mBaseEvaluator.evaluate_all\u001b[0;34m(self, jobs, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m()\n\u001b[1;32m    174\u001b[0m \u001b[39m# overwrite the default 10 progress reports  with 5 reports\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m callback \u001b[39m=\u001b[39m perform_experiments(\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_msis,\n\u001b[1;32m    177\u001b[0m     evaluator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    178\u001b[0m     reporting_frequency\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreporting_frequency,\n\u001b[1;32m    179\u001b[0m     scenarios\u001b[39m=\u001b[39;49mscenarios,\n\u001b[1;32m    180\u001b[0m     policies\u001b[39m=\u001b[39;49mpolicies,\n\u001b[1;32m    181\u001b[0m     return_callback\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    182\u001b[0m     log_progress\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    183\u001b[0m )\n\u001b[1;32m    185\u001b[0m experiments, outcomes \u001b[39m=\u001b[39m callback\u001b[39m.\u001b[39mget_results()\n\u001b[1;32m    187\u001b[0m \u001b[39mif\u001b[39;00m searchover \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mlevers\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39muncertainties\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ema_workbench/em_framework/evaluators.py:568\u001b[0m, in \u001b[0;36mperform_experiments\u001b[0;34m(models, scenarios, policies, evaluator, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, lever_sampling, callback, return_callback, combine, log_progress)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evaluator:\n\u001b[1;32m    566\u001b[0m     evaluator \u001b[39m=\u001b[39m SequentialEvaluator(models)\n\u001b[0;32m--> 568\u001b[0m evaluator\u001b[39m.\u001b[39;49mevaluate_experiments(scenarios, policies, callback, combine\u001b[39m=\u001b[39;49mcombine)\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m callback\u001b[39m.\u001b[39mi \u001b[39m!=\u001b[39m nr_of_exp:\n\u001b[1;32m    571\u001b[0m     \u001b[39mraise\u001b[39;00m EMAError(\n\u001b[1;32m    572\u001b[0m         (\n\u001b[1;32m    573\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39msome fatal error has occurred while \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m         )\u001b[39m.\u001b[39mformat(nr_of_exp, callback\u001b[39m.\u001b[39mi)\n\u001b[1;32m    577\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ema_workbench/em_framework/evaluators.py:415\u001b[0m, in \u001b[0;36mMultiprocessingEvaluator.evaluate_experiments\u001b[0;34m(self, scenarios, policies, callback, combine)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_experiments\u001b[39m(\u001b[39mself\u001b[39m, scenarios, policies, callback, combine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfactorial\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    414\u001b[0m     ex_gen \u001b[39m=\u001b[39m experiment_generator(scenarios, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_msis, policies, combine\u001b[39m=\u001b[39mcombine)\n\u001b[0;32m--> 415\u001b[0m     add_tasks(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_processes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool, ex_gen, callback)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ema_workbench/em_framework/ema_multiprocessing.py:284\u001b[0m, in \u001b[0;36madd_tasks\u001b[0;34m(n_processes, pool, experiments, callback)\u001b[0m\n\u001b[1;32m    281\u001b[0m feeder\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    282\u001b[0m reader\u001b[39m.\u001b[39mstart()\n\u001b[0;32m--> 284\u001b[0m feeder\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    285\u001b[0m results_queue\u001b[39m.\u001b[39mput(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    286\u001b[0m reader\u001b[39m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1133\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#'''\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "with MultiprocessingEvaluator(model, n_processes = 4) as evaluator:\n",
    "    results1, convergence = evaluator.optimize(nfe=nfe,\n",
    "                                            searchover='levers',\n",
    "                                            epsilons=[0.1]*len(model.outcomes),\n",
    "                                              convergence=convergence_metrics,\n",
    "                                            reference=ref_scenario\n",
    "                                            )\n",
    "    \n",
    "results1.to_csv('results/optimization_{}_{}.csv'.format(problem_formulation,nfe))\n",
    "\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final result data set\n",
    "results = pd.read_csv(\"results/optimization_6_200.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives results across each of the dike rings for problem_formulation (3)\n",
    "for i in range(5):\n",
    "\n",
    "        data = results.loc[:, [f\"A.{i+1}_Dike Investment Costs\",\n",
    "                               f\"A.{i+1}_Expected Annual Damage\",\n",
    "                               f\"A.{i+1}_Expected Number of Deaths\",\n",
    "                               ]]\n",
    "        \n",
    "        limits = parcoords.get_limits(data)\n",
    "        limits.loc[0, [f\"A.{i+1}_Expected Annual Damage\",\n",
    "                               f\"A.{i+1}_Expected Number of Deaths\",\n",
    "                               f\"A.{i+1}_Dike Investment Costs\",\n",
    "                               ]] = 0\n",
    "\n",
    "        paraxes = parcoords.ParallelAxes(limits)\n",
    "        paraxes.plot(data)\n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Re-Evaluate Solutions under Uncertainty (Few Candidate Policies, Many Scenario)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a Constrain Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create aggregate columns for death, damage and investment cost\n",
    "results[\"Gelderland_Deaths\"] = results[[f\"A.{i+1}_Expected Number of Deaths\" for i in range(3)]].sum(axis=1)\n",
    "results[\"Gelderland_Damages\"] = results[[f\"A.{i+1}_Expected Annual Damage\" for i in range(3)]].sum(axis=1)\n",
    "results[\"Gelderland_Investment\"] = results[[f\"A.{i+1}_Dike Investment Costs\" for i in range(3)]].sum(axis=1)\n",
    "results[\"Overijssel_Deaths\"] = results[[f\"A.{i}_Expected Number of Deaths\" for i in [4, 5]]].sum(axis=1)\n",
    "results[\"Overijssel_Damages\"] = results[[f\"A.{i}_Expected Annual Damage\" for i in [4, 5]]].sum(axis=1)\n",
    "results[\"Overijssel_Investment\"] = results[[f\"A.{i}_Dike Investment Costs\" for i in [4, 5]]].sum(axis=1)\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set threshiold for priority 1, 2 and 3: Deaths, Damages and Investment costs\n",
    "distribution_threshold_deaths = 0.2\n",
    "distribution_threshold_damages = 0.2\n",
    "distribution_threshold_investment = 0.2\n",
    "#Refine Policies-Dataframe to fit Priority 1 criterion\n",
    "results2 = results.sort_values(\"Gelderland_Deaths\")\n",
    "results2 = results.iloc[0:int(len(results2)*distribution_threshold_deaths),:]\n",
    "\n",
    "#Refine Policies-Dataframe to fit Priority 2 criterion\n",
    "results3 = results2.sort_values(\"Gelderland_Damages\")\n",
    "results3 = results3.iloc[0:int(len(results3)*distribution_threshold_damages),:]\n",
    "\n",
    "#Refine Policies-Dataframe to fit Priority 3 criterion\n",
    "results4 = results3.sort_values(\"Gelderland_Investment\")\n",
    "policies = results4.iloc[0:int(len(results4)*distribution_threshold_investment),:]\n",
    "\n",
    "policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives results across each of the dike rings for problem_formulation (3)\n",
    "for i in range(5):\n",
    "\n",
    "        data = policies.loc[:, [f\"A.{i+1}_Dike Investment Costs\",\n",
    "                               f\"A.{i+1}_Expected Annual Damage\",\n",
    "                               f\"A.{i+1}_Expected Number of Deaths\",\n",
    "                               ]]\n",
    "        \n",
    "        limits = parcoords.get_limits(data)\n",
    "        limits.loc[0, [f\"A.{i+1}_Expected Annual Damage\",\n",
    "                               f\"A.{i+1}_Expected Number of Deaths\",\n",
    "                               f\"A.{i+1}_Dike Investment Costs\",\n",
    "                               ]] = 0\n",
    "\n",
    "        paraxes = parcoords.ParallelAxes(limits)\n",
    "        paraxes.plot(data)\n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b Robustness Analysis (Run Scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policies are subsequently collected in a list as policy objects\n",
    "policies_to_evaluate = []\n",
    "\n",
    "for i, policy in policies.iterrows():\n",
    "    policies_to_evaluate.append(Policy(str(i), **policy.to_dict()))\n",
    "    \n",
    "#Analogous to the polciy class-instances, our scenario are collected in a list of scenario class instances\n",
    "scenarios = experiments.drop(columns=[\"policy\",\"model\"])\n",
    "scenario_dict = scenarios.to_dict('index')\n",
    "list_scenarios = []\n",
    "for key in scenario_dict.keys():\n",
    "    list_scenarios.append(Scenario(key,**scenario_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scenarios = 100\n",
    "'''\n",
    "\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    rob_results = evaluator.perform_experiments(n_scenarios,\n",
    "                                            policies_to_evaluate)\n",
    "    \n",
    "save_results(rob_results, 'results/MORDM2.tar.gz')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_results = load_results ('results/MORDM2.tar.gz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3c Visualize Results\n",
    "1) Signal to Noise Ratio\n",
    "2) Calculate Maximum regret\n",
    "3) Scenario Dicovery to understand bad conditions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3c1 Signal to Noise Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal to noise - high value for maximizable outcomes is desirable\n",
    "#outcome to have high average value and low standard deviation\n",
    "\n",
    "def s_to_n(data, direction):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    \n",
    "    if direction==ScalarOutcome.MAXIMIZE:\n",
    "        return mean/std\n",
    "    else:\n",
    "        return mean*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = rob_results\n",
    "\n",
    "overall_scores = {}\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    scores = {}\n",
    "    \n",
    "    logical = experiments['policy']==policy\n",
    "    \n",
    "    for outcome in model.outcomes:\n",
    "        value  = outcomes[outcome.name][logical]\n",
    "        sn_ratio = s_to_n(value, outcome.kind)\n",
    "        scores[outcome.name] = sn_ratio\n",
    "    overall_scores[policy] = scores\n",
    "scores = pd.DataFrame.from_dict(overall_scores).T\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scores\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['Expected Annual Damage', 'Total Investment Costs', 'Expected Number of Deaths']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for j, (ind, row) in enumerate(data.reset_index().iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=int(row['index']), color=colors[j])\n",
    "\n",
    "paraxes.legend()\n",
    "\n",
    "#paraxes.invert_axis('max_P')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3c2 Calculate Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regret(data, best):\n",
    "    return np.abs(best-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = rob_results\n",
    "\n",
    "overall_regret = {}\n",
    "max_regret = {}\n",
    "for outcome in model.outcomes:\n",
    "    policy_column = experiments['policy']\n",
    "    \n",
    "    # create a DataFrame with all the relevent information\n",
    "    # i.e., policy, scenario_id, and scores\n",
    "    data = pd.DataFrame({outcome.name: outcomes[outcome.name], \n",
    "                         \"policy\":experiments['policy'],\n",
    "                         \"scenario\":experiments['scenario']})\n",
    "    \n",
    "    # reorient the data by indexing with policy and scenario id\n",
    "    data = data.pivot(index='scenario', columns='policy')\n",
    "    \n",
    "    # flatten the resulting hierarchical index resulting from \n",
    "    # pivoting, (might be a nicer solution possible)\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "    \n",
    "    # we need to control the broadcasting. \n",
    "    # max returns a 1d vector across scenario id. By passing\n",
    "    # np.newaxis we ensure that the shape is the same as the data\n",
    "    # next we take the absolute value\n",
    "    #\n",
    "    # basically we take the difference of the maximum across \n",
    "    # the row and the actual values in the row\n",
    "    #\n",
    "    outcome_regret = (data.max(axis=1)[:, np.newaxis] - data).abs()\n",
    "    \n",
    "    overall_regret[outcome.name] = outcome_regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize as heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_regret = pd.DataFrame(max_regret)\n",
    "sns.heatmap(max_regret/max_regret.max(), cmap='viridis', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize as parallel axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette()\n",
    "\n",
    "data = max_regret\n",
    "\n",
    "# makes it easier to identify the policy associated with each line\n",
    "# in the parcoords plot\n",
    "# data['policy'] = data.index.astype(\"float64\")\n",
    "\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['Expected Annual Damage', 'Total Investment Costs', 'Expected Number of Deaths']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(index), color=colors[i])\n",
    "paraxes.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3c3 Scenario Discovery for some conditions (IF NECESSARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "from ema_workbench.analysis import prim\n",
    "\n",
    "x = \n",
    "y = \n",
    "\n",
    "prim_alg = prim.Prim(x, y, threshold=0.5)\n",
    "box = prim_alg.find_box()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box.inspect_tradeoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxno = 2\n",
    "#box.inspect(boxno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box.select(boxno)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ema",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
